{
 "cells": [
  {
   "cell_type": "raw",
   "id": "nominated-middle",
   "metadata": {},
   "source": [
    "Changes:\n",
    "\n",
    "- Remove BN, Lr: 1e-4\n",
    "\n",
    "THIS CODE IT FOR CONDITIONAL WAV-SEPARATION USING 'CLASS-SPECIFIC WAVEFORM' AS A CONDITIONAL ON NIGEN DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "automated-domain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "from asteroid_filterbanks import STFTFB, Encoder, Decoder\n",
    "from asteroid.masknn import TDConvNet , TDConvNetpp\n",
    "from asteroid_filterbanks import make_enc_dec\n",
    "from asteroid import ConvTasNet\n",
    "from asteroid.data import LibriMix\n",
    "from asteroid.losses import PITLossWrapper, pairwise_neg_sisdr\n",
    "from asteroid.data import LibriMix\n",
    "from asteroid.engine.system import System\n",
    "from asteroid.losses import PITLossWrapper, pairwise_neg_sisdr\n",
    "from asteroid import ConvTasNet\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "\n",
    "\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import IPython.display as ipd\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "\n",
    "from torchsummary import summary\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from torchvision import transforms, utils\n",
    "import torchaudio\n",
    "\n",
    "import torch.optim as optim\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "#device = 'cpu'\n",
    "import torch.nn.functional as F\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "perceived-narrow",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnNormedVector_oneSam(A = None):\n",
    "    \n",
    "    n_channels = 1\n",
    "    n_sam = A.shape[-1]\n",
    "    AA = A.clone()\n",
    "    t_zro = torch.zeros(n_channels, n_sam+1)\n",
    "    t_zro[:,:n_sam] = AA\n",
    "    AA = t_zro\n",
    "    \n",
    "    #AA = AA.view(A.size(0), -1)\n",
    "    AA -= AA.min(1, keepdim=True)[0]\n",
    "    AA /= AA.max(1, keepdim=True)[0]\n",
    "    AA = AA-AA[0][n_sam]\n",
    "    \n",
    "    AA = AA.view(n_channels, n_sam+1)\n",
    "    \n",
    "    return AA[:,:n_sam]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "completed-reporter",
   "metadata": {},
   "outputs": [],
   "source": [
    "class S2Lpairs_Dataset(Dataset):\n",
    "\n",
    "    def __init__(self, csv_file, wav_dir,mix_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file with annotations.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.frame_ = pd.read_csv(csv_file)\n",
    "        self.wav_dir = wav_dir\n",
    "        self.mix_dir = mix_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.frame_)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        spec = ['alarm','baby','crash','dog','engine','femaleScream',\n",
    "                 'femaleSpeech','fire','footsteps','knock','maleScream',\n",
    "                 'maleSpeech','phone','piano']\n",
    "        \n",
    "        _1 =            self.frame_.iloc[idx, 1] # First ROI\n",
    "        _2 =            self.frame_.iloc[idx, 2] # second ROI\n",
    "        pres_abs =      self.frame_.iloc[idx, 4] # 0 or 1\n",
    "        cond_look_for = self.frame_.iloc[idx, 3] # Conditional. This is what we are looking for.\n",
    "        \n",
    "        spec.index(cond_look_for) + 1\n",
    "        cond = np.zeros(14) # <<-- No. of Classes 14 in case of NIGEN\n",
    "        cond[spec.index(cond_look_for)] = 1\n",
    "        cond_ = torch.from_numpy(np.float32(cond)) # This is what to look for, hence a conditional\n",
    "        cond_ = cond_.unsqueeze(0)\n",
    "        \n",
    "        class_spec_cond_wav = random.sample(sorted(os.listdir(self.wav_dir +cond_look_for)), 1)\n",
    "        \n",
    "        _1_sam, sr = torchaudio.load(self.wav_dir +(_1.split('_')[3]) + '/' + _1)\n",
    "        _2_sam, sr = torchaudio.load(self.wav_dir + (_2.split('_')[3]) + '/' + _2)\n",
    "        #_cond_sam, sr = torchaudio.load(self.wav_dir + cond_look_for + '/' + class_spec_cond_wav[0])\n",
    "        \n",
    "        mix_pth = self.mix_dir + _1.split('.wav')[0] + '_' + _2\n",
    "        #print(\">> Trying to open mix dir:\", mix_pth)\n",
    "        \n",
    "        mix_1_2, sr = torchaudio.load(mix_pth)\n",
    "        \n",
    "        #_1_sam = returnNormedVector_oneSam(A = _1_sam)\n",
    "        #_2_sam = returnNormedVector_oneSam(A = _2_sam)\n",
    "        \n",
    "        #mix_1_2 = _1_sam + _2_sam\n",
    "        #mix_1_2 = returnNormedVector_oneSam(A = mix_1_2)\n",
    "        \n",
    "        if (pres_abs == 1):\n",
    "            if(cond_look_for in _1):\n",
    "                desired_sep = _1_sam\n",
    "                \n",
    "            elif(cond_look_for in _2):\n",
    "                desired_sep = _2_sam\n",
    "                \n",
    "            \n",
    "        elif (pres_abs == 0):\n",
    "            desired_sep = torch.from_numpy(np.float32(np.zeros(_2_sam.shape[1])))\n",
    "            desired_sep = torch.unsqueeze(desired_sep, 0)\n",
    "        \n",
    "        \n",
    "        if self.transform: # May have to normalize (at the bottom) and resample and shit...\n",
    "            desired_sep = self.transform(desired_sep) #16kz to 8kz\n",
    "            mix_1_2 = self.transform(mix_1_2) #16kz to 8kz\n",
    "            \n",
    "        sample = {'conditional': cond_, 'sum_1_2': mix_1_2, 'separation': desired_sep, 'pres_abs':pres_abs}#, 'pres_abs_bin_flag': pres_abs_binaryFlag}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "charged-dragon",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Conditional tensor: torch.Size([24, 1, 14]) \n",
      " Mixture Tensor:  torch.Size([24, 1, 32000]) \n",
      " Present/ Absent: torch.Size([24])\n",
      "\n",
      " -------------------------- Batch Number ----------------------------: 0\n",
      "\n",
      " Conditional tensor: torch.Size([24, 1, 14]) \n",
      " Mixture Tensor:  torch.Size([24, 1, 32000]) \n",
      " Present/ Absent: torch.Size([24])\n",
      "\n",
      " -------------------------- Batch Number ----------------------------: 1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "tr_d_ds = S2Lpairs_Dataset(csv_file = '/home/shree//21/cond_sep/icassp2022/from_server/nigen/icassp22_exp/processed_data/csv/tr_combinations_large.csv',\n",
    "                     wav_dir = '/home/shree//21/cond_sep/icassp2022/from_server/nigen/icassp22_exp/processed_data/split2sec/',\n",
    "                     mix_dir = '/home/shree//21/cond_sep/icassp2022/from_server/nigen/icassp22_exp/processed_data/processed_mixed_data/tr/',\n",
    "                     transform = torchaudio.transforms.Resample(16000, 16000))\n",
    "\n",
    "val_d_ds = S2Lpairs_Dataset(csv_file = '/home/shree//21/cond_sep/icassp2022/from_server/nigen/icassp22_exp/processed_data/csv/val_combinations.csv',\n",
    "                     wav_dir = '/home/shree//21/cond_sep/icassp2022/from_server/nigen/icassp22_exp/processed_data/val/',\n",
    "                     mix_dir = '/home/shree//21/cond_sep/icassp2022/from_server/nigen/icassp22_exp/processed_data/processed_mixed_data/val/',\n",
    "                     transform = torchaudio.transforms.Resample(16000, 16000))\n",
    "\n",
    "BATCH_SIZE = 24\n",
    "\n",
    "# Setup the Dataloaders\n",
    "tr_dataloader = DataLoader(tr_d_ds, batch_size = BATCH_SIZE, shuffle = True, num_workers = 0) # there's also drop_last = False, collate_fn, etc.\n",
    "val_dataloader = DataLoader(val_d_ds, batch_size = BATCH_SIZE, shuffle = False, num_workers = 0) # there's also drop_last = False, collate_fn, etc.\n",
    "\n",
    "for b_no,sample_batched in enumerate(val_dataloader):\n",
    "    print(\"\\n Conditional tensor:\",sample_batched['conditional'].size(),\n",
    "          \"\\n Mixture Tensor: \",sample_batched['sum_1_2'].size(),\n",
    "          \"\\n Present/ Absent:\",sample_batched['pres_abs'].size())\n",
    "    \n",
    "    print(\"\\n -------------------------- Batch Number ----------------------------:\",b_no)\n",
    "    \n",
    "    if(b_no == 1):\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "british-submission",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n",
      "torch.Size([10, 1, 32000]) torch.Size([10, 1])\n"
     ]
    }
   ],
   "source": [
    "# Model definition based on the design of model #1\n",
    "\n",
    "from asteroid_filterbanks import make_enc_dec\n",
    "from asteroid_filterbanks import STFTFB\n",
    "\n",
    "class Model(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "        fb = STFTFB(n_filters=256, kernel_size=128, stride=64)\n",
    "        self.enc = Encoder(fb)\n",
    "        self.cond_enc = Encoder(fb)\n",
    "     \n",
    "        \n",
    "        decoder_fb = STFTFB(n_filters=514, kernel_size=128, stride=64)\n",
    "        self.dec = Decoder(decoder_fb)\n",
    "        \n",
    "        self.masker = TDConvNet(in_chan=516, \n",
    "                                n_src=1)\n",
    "        self.m = nn.Linear(14, 64) \n",
    "        self.m2 = nn.Linear(64, 499)\n",
    "        \n",
    "        self.dropout = nn.Dropout(0.25)\n",
    "        \n",
    "        self.c1 = nn.Conv1d(in_channels=1, out_channels= 258, kernel_size = 3, stride=1,padding = 1,  padding_mode ='zeros')\n",
    "        self.bn1 = nn.BatchNorm1d(258)\n",
    "        \n",
    "        self.c1d_1 = nn.Conv1d(in_channels=516, out_channels= 516, kernel_size = 3, stride=1,padding = 1,  padding_mode ='zeros')\n",
    "        self.bn2 = nn.BatchNorm1d(516)\n",
    "        \n",
    "        \n",
    "        # For the FC layers in the binary Classification\n",
    "        self.co_fc_1 = nn.Conv1d(in_channels=516, out_channels= 1, kernel_size = 3, stride=1,padding = 1,  padding_mode ='zeros')\n",
    "        \n",
    "            \n",
    "        # Number of input features is 516x499.\n",
    "        self.fc1 = nn.Linear(499, 32) \n",
    "        self.fc2 = nn.Linear(32, 1)\n",
    "        #self.fc3 = nn.Linear(32, 1) \n",
    "        \n",
    "        #self.relu = nn.ReLU()\n",
    "        self.dropout_2 = nn.Dropout(p=0.1)\n",
    "        self.batchnorm1 = nn.BatchNorm1d(64)\n",
    "        self.batchnorm2 = nn.BatchNorm1d(64)\n",
    "        #self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, wav, cond_wav):\n",
    "        \n",
    "        #print(\"Shapes of the input mix and cond:\")\n",
    "        #print(wav.shape)\n",
    "        #print(cond_wav.shape)\n",
    "        tf_rep = self.enc(wav)\n",
    "        #print(\"00_tf_rep\",tf_rep.shape)\n",
    "\n",
    "        m_out = self.m(cond_wav)\n",
    "        m_out = F.relu(m_out) # need dropout\n",
    "        m_out = self.dropout(m_out)\n",
    "        #print(\"01_m_out\", m_out.shape)\n",
    "        \n",
    "        m2_out = self.m2(m_out)\n",
    "        m2_out = F.relu(m2_out) # need dropout, changed to sigmoid from relu\n",
    "        m2_out = self.dropout(m2_out)\n",
    "        #print(\"01_m2_out\", m2_out.shape)\n",
    "        \n",
    "        c1_out = self.c1(m2_out)\n",
    "        c1_out = F.relu(self.bn1(c1_out))\n",
    "        #print(\"01_c1_out\", c1_out.shape)\n",
    "                \n",
    "        concat_in = torch.cat((tf_rep, c1_out),dim=1)\n",
    "        #print(\"03_concat_in:\",concat_in.shape)\n",
    "        \n",
    "        c1d_1_out = self.c1d_1(concat_in)\n",
    "        c1d_1_out = F.relu((c1d_1_out)) # removed <self.bn2> from here\n",
    "        #print(\"04_c1d_1_out:\",c1d_1_out.shape)\n",
    "\n",
    "        masks = self.masker(c1d_1_out)\n",
    "        #print(\"04_masks Shape: \",masks.shape)\n",
    "        #print(\"Concat the above 04s\")\n",
    "        \n",
    "        con_usq = c1d_1_out.unsqueeze(1) * masks\n",
    "        #print(\"Post mask multiplication, con_usq:\", con_usq.shape)\n",
    "        \n",
    "        # Add the pres_abs binary detector here\n",
    "        co_fc_1_out = self.co_fc_1(con_usq.squeeze(1))\n",
    "        #print(\"05_co_fc_1_out\",co_fc_1_out.shape)\n",
    "        \n",
    "        x = co_fc_1_out.view(-1, 499)\n",
    "        x = self.dropout_2(F.relu(self.fc1(x)))\n",
    "        x = self.sigmoid(self.fc2(x)) # Pres/abs\n",
    "        \n",
    "        wavs_out = self.dec(con_usq) # output sep waveform\n",
    "        \n",
    "        return wavs_out, x\n",
    "\n",
    "print(device)\n",
    "# Define and forward \n",
    "cond_conv_tasnet = Model()\n",
    "cond_conv_tasnet.to(device)\n",
    "wav_out, pres_abs = cond_conv_tasnet(wav = torch.randn(10, 1, 32000).to(device), cond_wav = torch.randn(10, 1, 14).to(device))   \n",
    "print(wav_out.shape, pres_abs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "freelance-happening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of parameters: 5822246\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(cond_conv_tasnet):\n",
    "    return sum(p.numel() for p in cond_conv_tasnet.parameters() if p.requires_grad)\n",
    "\n",
    "n = count_parameters(cond_conv_tasnet)\n",
    "print(\"Number of parameters: %s\" % n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "competitive-challenge",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up loss funcion\n",
    "loss_func = PITLossWrapper(pairwise_neg_sisdr, pit_from='pw_mtx')\n",
    "\n",
    "#optimizer = optim.Adam(model.parameters(), lr=1e-3, weight_decay=0.0001)\n",
    "#scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=20, gamma=0.1)  # reduce the \n",
    "optimizer = optim.Adam(cond_conv_tasnet.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "determined-vienna",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"PATH = '../../../icassp2022/model123/Model2/saved_model/model2-5M_EP_last.pt'\\nPATH = './saved_model/ohot_m00-5M_EP_35.pt'\\n\\n\\ncond_conv_tasnet.load_state_dict(torch.load(PATH))\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''PATH = '../../../icassp2022/model123/Model2/saved_model/model2-5M_EP_last.pt'\n",
    "PATH = './saved_model/ohot_m00-5M_EP_35.pt'\n",
    "\n",
    "\n",
    "cond_conv_tasnet.load_state_dict(torch.load(PATH))'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "designed-cathedral",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.metrics\n",
    "\n",
    "def get_accuracy(y_true, y_prob):\n",
    "    accuracy = sklearn.metrics.accuracy_score(y_true, y_prob > 0.5)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rocky-directory",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, epoch):\n",
    "    model.train() # you need this to turn on the 'training' of certain aspects of the model like the BN and dropout\n",
    "    # During evaluation/ inference, you should use model.eval()\n",
    "    \n",
    "    acc_acc = 0\n",
    "    for batch_idx, sample_batched in enumerate(tr_dataloader):\n",
    "        # data_1 = mixture | size 32000\n",
    "        # data_2 = conditional | size 8\n",
    "        \n",
    "        \n",
    "        sum_1_2 = sample_batched['sum_1_2'].to(device) # Mixture of two ROIs\n",
    "        cond_lookUp = sample_batched['conditional'].to(device) # Conditional/What to Look for\n",
    "        target = sample_batched['separation'].to(device) # Desired Separation\n",
    "        x_target = sample_batched['pres_abs'].to(device).unsqueeze(1) # Fixing the Pres/abd binary array!\n",
    "        x_target = x_target.to(torch.float32)\n",
    "        \n",
    "        output, x_out = model(wav = sum_1_2, cond_wav = cond_lookUp)\n",
    "\n",
    "        loss_func = PITLossWrapper(pairwise_neg_sisdr, pit_from='pw_mtx')\n",
    "        loss = loss_func(target, output)\n",
    "        \n",
    "        bce_loss_func = nn.BCELoss()\n",
    "        try:\n",
    "            bce_loss = bce_loss_func(x_out, x_target)\n",
    "           \n",
    "        except:\n",
    "            print(\"Error occurs here, output:\", x_out)\n",
    "            print(\"Error occurs here, target:\", x_target)\n",
    "            print(\">>> INPUT <<\")\n",
    "            print(\"Input Mixture:\",sum_1_2)\n",
    "            print(\"Conditional\",cond_lookUp)\n",
    "            print(\"Detection Target\",x_target)\n",
    "            print(\"Separation Desired:\",target)\n",
    "            \n",
    "            joblib.dump(sum_1_2,'./problem_inputs/dual_sum_1_2.pkl')\n",
    "            joblib.dump(cond_lookUp, './problem_inputs/dual_cond_lookUp.pkl')\n",
    "            joblib.dump(x_target, './problem_inputs/dual_x_target.pkl')\n",
    "            joblib.dump(target, \"./problem_inputs/dual_sep_target.pkl\")\n",
    "            \n",
    "        loss = loss + bce_loss\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        acc = get_accuracy(torch.squeeze(x_target,1).cpu().data.numpy(), torch.squeeze(x_out,1).cpu().data.numpy())\n",
    "        acc_acc += acc\n",
    "            \n",
    "        # print training stats\n",
    "        if batch_idx % 10000 == 0:\n",
    "            print(f\"Train Epoch: {epoch} [{batch_idx * len(sum_1_2)}/{len(tr_dataloader.dataset)} ({100. * batch_idx / len(tr_dataloader):.0f}%)]\\tLoss: {loss.item():.6f}\")\n",
    "            print(\"Batch_idx:\",batch_idx,\"|| Accuracy:\",acc,\"||AccAcc:\",acc_acc/(batch_idx+1))\n",
    "        \n",
    "        losses.append(loss.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99beb6a0-3e48-4fc3-a864-1c5385d0fbee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dress-calcium",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model):\n",
    "    \n",
    "    cond_conv_tasnet.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    best_loss = 1\n",
    "    acc_acc = 0\n",
    "    \n",
    "    example_images = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, sample_batched in enumerate(val_dataloader):\n",
    "\n",
    "            sum_1_2 = sample_batched['sum_1_2'].to(device) # Mixture of two ROIs\n",
    "            cond_lookUp = sample_batched['conditional'].to(device) # Conditional/What to Look for\n",
    "            target = sample_batched['separation'].to(device) # Desired Separation\n",
    "            x_target = sample_batched['pres_abs'].to(device).unsqueeze(1) # Fixing the Pres/abd binary array!\n",
    "            x_target = x_target.to(torch.float32)\n",
    "\n",
    "            output, x_out = model(wav = sum_1_2, cond_wav = cond_lookUp)\n",
    "            \n",
    "            acc = get_accuracy(torch.squeeze(x_target,1).cpu().data.numpy(), torch.squeeze(x_out,1).cpu().data.numpy())\n",
    "            acc_acc += acc\n",
    "            \n",
    "            if batch_idx % 10 == 0:\n",
    "                print(\"Batch_idx:\",batch_idx,\"|| Accuracy:\",acc,\"||AccAcc:\",acc_acc/(batch_idx+1))\n",
    "                #print(f\"Train: {batch_idx} [{batch_idx * len(cond_lookUp)}/{len(val_dataloader.dataset)} ({100. * batch_idx / len(val_dataloader):.0f}%)]\\tLoss: {test_loss.item():.6f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ideal-dollar",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train:\n",
      "Train Epoch: 1 [0/551359 (0%)]\tLoss: 62.574856\n",
      "Batch_idx: 0 || Accuracy: 0.3333333333333333 ||AccAcc: 0.3333333333333333\n",
      "Train Epoch: 1 [240000/551359 (44%)]\tLoss: 48.251163\n",
      "Batch_idx: 10000 || Accuracy: 0.6666666666666666 ||AccAcc: 0.6905976069059733\n",
      "Train Epoch: 1 [480000/551359 (87%)]\tLoss: 46.924068\n",
      "Batch_idx: 20000 || Accuracy: 0.7916666666666666 ||AccAcc: 0.696640167991599\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.0 ||AccAcc: 0.0\n",
      "Batch_idx: 10 || Accuracy: 0.5 ||AccAcc: 0.4659090909090909\n",
      "Batch_idx: 20 || Accuracy: 0.2916666666666667 ||AccAcc: 0.46626984126984117\n",
      "Batch_idx: 30 || Accuracy: 0.4583333333333333 ||AccAcc: 0.49059139784946226\n",
      "Batch_idx: 40 || Accuracy: 0.45 ||AccAcc: 0.506910569105691\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 2 [0/551359 (0%)]\tLoss: 38.753296\n",
      "Batch_idx: 0 || Accuracy: 0.6666666666666666 ||AccAcc: 0.6666666666666666\n",
      "Train Epoch: 2 [240000/551359 (44%)]\tLoss: 34.303852\n",
      "Batch_idx: 10000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.7167116621671157\n",
      "Train Epoch: 2 [480000/551359 (87%)]\tLoss: 32.695862\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.7301718247420944\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.0 ||AccAcc: 0.0\n",
      "Batch_idx: 10 || Accuracy: 0.5 ||AccAcc: 0.5151515151515151\n",
      "Batch_idx: 20 || Accuracy: 0.5416666666666666 ||AccAcc: 0.509920634920635\n",
      "Batch_idx: 30 || Accuracy: 0.625 ||AccAcc: 0.5309139784946237\n",
      "Batch_idx: 40 || Accuracy: 0.55 ||AccAcc: 0.5347560975609758\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 3 [0/551359 (0%)]\tLoss: 33.383434\n",
      "Batch_idx: 0 || Accuracy: 0.75 ||AccAcc: 0.75\n",
      "Train Epoch: 3 [240000/551359 (44%)]\tLoss: 40.677769\n",
      "Batch_idx: 10000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.7817384928173854\n",
      "Train Epoch: 3 [480000/551359 (87%)]\tLoss: 40.507576\n",
      "Batch_idx: 20000 || Accuracy: 0.75 ||AccAcc: 0.7919187373964647\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.125 ||AccAcc: 0.125\n",
      "Batch_idx: 10 || Accuracy: 0.5416666666666666 ||AccAcc: 0.5189393939393939\n",
      "Batch_idx: 20 || Accuracy: 0.4583333333333333 ||AccAcc: 0.5396825396825398\n",
      "Batch_idx: 30 || Accuracy: 0.7916666666666666 ||AccAcc: 0.5712365591397851\n",
      "Batch_idx: 40 || Accuracy: 0.65 ||AccAcc: 0.5930894308943091\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 4 [0/551359 (0%)]\tLoss: 28.732006\n",
      "Batch_idx: 0 || Accuracy: 0.7916666666666666 ||AccAcc: 0.7916666666666666\n",
      "Train Epoch: 4 [240000/551359 (44%)]\tLoss: 49.552536\n",
      "Batch_idx: 10000 || Accuracy: 0.875 ||AccAcc: 0.8283796620337979\n",
      "Train Epoch: 4 [480000/551359 (87%)]\tLoss: 36.255501\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.8357019649017551\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.20833333333333334 ||AccAcc: 0.20833333333333334\n",
      "Batch_idx: 10 || Accuracy: 0.2916666666666667 ||AccAcc: 0.5492424242424243\n",
      "Batch_idx: 20 || Accuracy: 0.5416666666666666 ||AccAcc: 0.5654761904761905\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.614247311827957\n",
      "Batch_idx: 40 || Accuracy: 0.75 ||AccAcc: 0.6473577235772358\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 5 [0/551359 (0%)]\tLoss: 30.255613\n",
      "Batch_idx: 0 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583333333333334\n",
      "Train Epoch: 5 [240000/551359 (44%)]\tLoss: 56.926163\n",
      "Batch_idx: 10000 || Accuracy: 0.875 ||AccAcc: 0.8572684398226832\n",
      "Train Epoch: 5 [480000/551359 (87%)]\tLoss: 39.575153\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.8628464410112832\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.125 ||AccAcc: 0.125\n",
      "Batch_idx: 10 || Accuracy: 0.3333333333333333 ||AccAcc: 0.5189393939393938\n",
      "Batch_idx: 20 || Accuracy: 0.5416666666666666 ||AccAcc: 0.5257936507936508\n",
      "Batch_idx: 30 || Accuracy: 0.7916666666666666 ||AccAcc: 0.6008064516129032\n",
      "Batch_idx: 40 || Accuracy: 0.85 ||AccAcc: 0.6660569105691058\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 6 [0/551359 (0%)]\tLoss: 32.416985\n",
      "Batch_idx: 0 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9166666666666666\n",
      "Train Epoch: 6 [240000/551359 (44%)]\tLoss: 36.751831\n",
      "Batch_idx: 10000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.8837157950871554\n",
      "Train Epoch: 6 [480000/551359 (87%)]\tLoss: 41.278076\n",
      "Batch_idx: 20000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.8865827541956296\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5833333333333334 ||AccAcc: 0.5833333333333334\n",
      "Batch_idx: 10 || Accuracy: 0.4166666666666667 ||AccAcc: 0.6780303030303032\n",
      "Batch_idx: 20 || Accuracy: 0.75 ||AccAcc: 0.6845238095238096\n",
      "Batch_idx: 30 || Accuracy: 0.7916666666666666 ||AccAcc: 0.6922043010752689\n",
      "Batch_idx: 40 || Accuracy: 0.75 ||AccAcc: 0.7073170731707318\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 7 [0/551359 (0%)]\tLoss: 38.997982\n",
      "Batch_idx: 0 || Accuracy: 0.8333333333333334 ||AccAcc: 0.8333333333333334\n",
      "Train Epoch: 7 [240000/551359 (44%)]\tLoss: 32.875557\n",
      "Batch_idx: 10000 || Accuracy: 0.6666666666666666 ||AccAcc: 0.9018139852681353\n",
      "Train Epoch: 7 [480000/551359 (87%)]\tLoss: 49.220898\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9061380264320192\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.3333333333333333 ||AccAcc: 0.3333333333333333\n",
      "Batch_idx: 10 || Accuracy: 0.4583333333333333 ||AccAcc: 0.5833333333333333\n",
      "Batch_idx: 20 || Accuracy: 0.8333333333333334 ||AccAcc: 0.621031746031746\n",
      "Batch_idx: 30 || Accuracy: 0.7916666666666666 ||AccAcc: 0.6706989247311831\n",
      "Batch_idx: 40 || Accuracy: 0.85 ||AccAcc: 0.7087398373983742\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 8 [0/551359 (0%)]\tLoss: 23.546444\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 8 [240000/551359 (44%)]\tLoss: 34.815430\n",
      "Batch_idx: 10000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9191372529413694\n",
      "Train Epoch: 8 [480000/551359 (87%)]\tLoss: 55.724152\n",
      "Batch_idx: 20000 || Accuracy: 0.875 ||AccAcc: 0.9209789510524523\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.3333333333333333 ||AccAcc: 0.3333333333333333\n",
      "Batch_idx: 10 || Accuracy: 0.5416666666666666 ||AccAcc: 0.6363636363636364\n",
      "Batch_idx: 20 || Accuracy: 0.8333333333333334 ||AccAcc: 0.6369047619047619\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.704301075268817\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.7567073170731707\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 9 [0/551359 (0%)]\tLoss: 36.024921\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 9 [240000/551359 (44%)]\tLoss: 30.882231\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9279030430290282\n",
      "Train Epoch: 9 [480000/551359 (87%)]\tLoss: 37.395599\n",
      "Batch_idx: 20000 || Accuracy: 0.875 ||AccAcc: 0.9301389097211905\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5 ||AccAcc: 0.5\n",
      "Batch_idx: 10 || Accuracy: 0.4583333333333333 ||AccAcc: 0.6666666666666667\n",
      "Batch_idx: 20 || Accuracy: 0.75 ||AccAcc: 0.6805555555555556\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7258064516129031\n",
      "Batch_idx: 40 || Accuracy: 0.85 ||AccAcc: 0.7514227642276423\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 10 [0/551359 (0%)]\tLoss: 47.835686\n",
      "Batch_idx: 0 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9166666666666666\n",
      "Train Epoch: 10 [240000/551359 (44%)]\tLoss: 39.233864\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9370396293703996\n",
      "Train Epoch: 10 [480000/551359 (87%)]\tLoss: 31.690445\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.937405213072696\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5833333333333334 ||AccAcc: 0.5833333333333334\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.6666666666666667\n",
      "Batch_idx: 20 || Accuracy: 0.7916666666666666 ||AccAcc: 0.6765873015873015\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.7298387096774195\n",
      "Batch_idx: 40 || Accuracy: 0.8 ||AccAcc: 0.7634146341463416\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 11 [0/551359 (0%)]\tLoss: 26.919901\n",
      "Batch_idx: 0 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583333333333334\n",
      "Train Epoch: 11 [240000/551359 (44%)]\tLoss: 52.959797\n",
      "Batch_idx: 10000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9417724894177257\n",
      "Train Epoch: 11 [480000/551359 (87%)]\tLoss: 49.532715\n",
      "Batch_idx: 20000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9424903754812357\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.2916666666666667 ||AccAcc: 0.2916666666666667\n",
      "Batch_idx: 10 || Accuracy: 0.5 ||AccAcc: 0.6401515151515151\n",
      "Batch_idx: 20 || Accuracy: 0.7083333333333334 ||AccAcc: 0.617063492063492\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.6935483870967742\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.7434959349593495\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 12 [0/551359 (0%)]\tLoss: 29.578716\n",
      "Batch_idx: 0 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583333333333334\n",
      "Train Epoch: 12 [240000/551359 (44%)]\tLoss: 46.858658\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9471594507215925\n",
      "Train Epoch: 12 [480000/551359 (87%)]\tLoss: 23.935503\n",
      "Batch_idx: 20000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9474109627852009\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.6666666666666666 ||AccAcc: 0.6666666666666666\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.7424242424242425\n",
      "Batch_idx: 20 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7420634920634922\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.7715053763440861\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.799390243902439\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 13 [0/551359 (0%)]\tLoss: 42.002781\n",
      "Batch_idx: 0 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583333333333334\n",
      "Train Epoch: 13 [240000/551359 (44%)]\tLoss: 41.139202\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9520964570209652\n",
      "Train Epoch: 13 [480000/551359 (87%)]\tLoss: 38.225746\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9517836608169638\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.625 ||AccAcc: 0.625\n",
      "Batch_idx: 10 || Accuracy: 0.4583333333333333 ||AccAcc: 0.6666666666666666\n",
      "Batch_idx: 20 || Accuracy: 0.6666666666666666 ||AccAcc: 0.6746031746031745\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7325268817204298\n",
      "Batch_idx: 40 || Accuracy: 0.85 ||AccAcc: 0.7717479674796747\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 14 [0/551359 (0%)]\tLoss: 34.665245\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 14 [240000/551359 (44%)]\tLoss: 27.890715\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9549420057994117\n",
      "Train Epoch: 14 [480000/551359 (87%)]\tLoss: 42.049728\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.955200156658837\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5416666666666666 ||AccAcc: 0.5416666666666666\n",
      "Batch_idx: 10 || Accuracy: 0.5 ||AccAcc: 0.6818181818181818\n",
      "Batch_idx: 20 || Accuracy: 0.75 ||AccAcc: 0.6865079365079364\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.7419354838709675\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.7841463414634144\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 15 [0/551359 (0%)]\tLoss: 39.321377\n",
      "Batch_idx: 0 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9166666666666666\n",
      "Train Epoch: 15 [240000/551359 (44%)]\tLoss: 26.591810\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583708295837073\n",
      "Train Epoch: 15 [480000/551359 (87%)]\tLoss: 53.033966\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9580479309367922\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.7916666666666666 ||AccAcc: 0.7916666666666666\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.7575757575757575\n",
      "Batch_idx: 20 || Accuracy: 0.7916666666666666 ||AccAcc: 0.7499999999999998\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.7889784946236559\n",
      "Batch_idx: 40 || Accuracy: 0.85 ||AccAcc: 0.8154471544715446\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 16 [0/551359 (0%)]\tLoss: 23.904570\n",
      "Batch_idx: 0 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583333333333334\n",
      "Train Epoch: 16 [240000/551359 (44%)]\tLoss: 57.040367\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.960520614605203\n",
      "Train Epoch: 16 [480000/551359 (87%)]\tLoss: 49.538151\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9607665450060907\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5416666666666666 ||AccAcc: 0.5416666666666666\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.7196969696969696\n",
      "Batch_idx: 20 || Accuracy: 0.75 ||AccAcc: 0.7202380952380952\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.7688172043010754\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.8067073170731708\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 17 [0/551359 (0%)]\tLoss: 27.749121\n",
      "Batch_idx: 0 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9166666666666666\n",
      "Train Epoch: 17 [240000/551359 (44%)]\tLoss: 47.802792\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9637827883878213\n",
      "Train Epoch: 17 [480000/551359 (87%)]\tLoss: 41.609940\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9636559838674745\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.2916666666666667 ||AccAcc: 0.2916666666666667\n",
      "Batch_idx: 10 || Accuracy: 0.5 ||AccAcc: 0.6401515151515151\n",
      "Batch_idx: 20 || Accuracy: 0.7083333333333334 ||AccAcc: 0.6408730158730158\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.7177419354838709\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.7680894308943089\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 18 [0/551359 (0%)]\tLoss: 26.963644\n",
      "Batch_idx: 0 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583333333333334\n",
      "Train Epoch: 18 [240000/551359 (44%)]\tLoss: 30.617416\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9644327233943234\n",
      "Train Epoch: 18 [480000/551359 (87%)]\tLoss: 52.977970\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9639955502224928\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.2916666666666667 ||AccAcc: 0.2916666666666667\n",
      "Batch_idx: 10 || Accuracy: 0.5416666666666666 ||AccAcc: 0.6287878787878789\n",
      "Batch_idx: 20 || Accuracy: 0.6666666666666666 ||AccAcc: 0.6388888888888888\n",
      "Batch_idx: 30 || Accuracy: 0.9166666666666666 ||AccAcc: 0.7150537634408601\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.7691056910569105\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 19 [0/551359 (0%)]\tLoss: 46.396088\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 19 [240000/551359 (44%)]\tLoss: 46.981850\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9661908809119075\n",
      "Train Epoch: 19 [480000/551359 (87%)]\tLoss: 42.555660\n",
      "Batch_idx: 20000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9657392130393493\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.375 ||AccAcc: 0.375\n",
      "Batch_idx: 10 || Accuracy: 0.5416666666666666 ||AccAcc: 0.6818181818181819\n",
      "Batch_idx: 20 || Accuracy: 0.8333333333333334 ||AccAcc: 0.6825396825396827\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.7473118279569892\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.7863821138211382\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 20 [0/551359 (0%)]\tLoss: 31.161411\n",
      "Batch_idx: 0 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9166666666666666\n",
      "Train Epoch: 20 [240000/551359 (44%)]\tLoss: 33.857822\n",
      "Batch_idx: 10000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9684698196847001\n",
      "Train Epoch: 20 [480000/551359 (87%)]\tLoss: 30.411512\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9673599653350708\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5 ||AccAcc: 0.5\n",
      "Batch_idx: 10 || Accuracy: 0.625 ||AccAcc: 0.712121212121212\n",
      "Batch_idx: 20 || Accuracy: 0.875 ||AccAcc: 0.7103174603174601\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7594086021505375\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.7963414634146341\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 21 [0/551359 (0%)]\tLoss: 28.559206\n",
      "Batch_idx: 0 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583333333333334\n",
      "Train Epoch: 21 [240000/551359 (44%)]\tLoss: 34.179855\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9688697796886968\n",
      "Train Epoch: 21 [480000/551359 (87%)]\tLoss: 47.692131\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9689411362765213\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5 ||AccAcc: 0.5\n",
      "Batch_idx: 10 || Accuracy: 0.5416666666666666 ||AccAcc: 0.6856060606060607\n",
      "Batch_idx: 20 || Accuracy: 0.6666666666666666 ||AccAcc: 0.6686507936507936\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7338709677419355\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.7823170731707317\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 22 [0/551359 (0%)]\tLoss: 32.315388\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 22 [240000/551359 (44%)]\tLoss: 29.480295\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9704946172049439\n",
      "Train Epoch: 22 [480000/551359 (87%)]\tLoss: 41.746586\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9705202239888049\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.625 ||AccAcc: 0.625\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.7348484848484848\n",
      "Batch_idx: 20 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7202380952380952\n",
      "Batch_idx: 30 || Accuracy: 0.9166666666666666 ||AccAcc: 0.7594086021505375\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.7902439024390242\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 23 [0/551359 (0%)]\tLoss: 25.252687\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 23 [240000/551359 (44%)]\tLoss: 30.179562\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9730193647301923\n",
      "Train Epoch: 23 [480000/551359 (87%)]\tLoss: 33.536167\n",
      "Batch_idx: 20000 || Accuracy: 0.875 ||AccAcc: 0.9722951352432413\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.625 ||AccAcc: 0.625\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.6136363636363635\n",
      "Batch_idx: 20 || Accuracy: 0.625 ||AccAcc: 0.5793650793650794\n",
      "Batch_idx: 30 || Accuracy: 0.9166666666666666 ||AccAcc: 0.6478494623655914\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.7099593495934958\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 24 [0/551359 (0%)]\tLoss: 19.468567\n",
      "Batch_idx: 0 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9166666666666666\n",
      "Train Epoch: 24 [240000/551359 (44%)]\tLoss: 32.253937\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9742400759923986\n",
      "Train Epoch: 24 [480000/551359 (87%)]\tLoss: 26.690863\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9733638318084105\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.4583333333333333 ||AccAcc: 0.4583333333333333\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.7083333333333334\n",
      "Batch_idx: 20 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7043650793650793\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7620967741935482\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.8034552845528453\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 25 [0/551359 (0%)]\tLoss: 22.058054\n",
      "Batch_idx: 0 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583333333333334\n",
      "Train Epoch: 25 [240000/551359 (44%)]\tLoss: 46.850529\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9751441522514387\n",
      "Train Epoch: 25 [480000/551359 (87%)]\tLoss: 36.684509\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9747825108744576\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5 ||AccAcc: 0.5\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.7272727272727273\n",
      "Batch_idx: 20 || Accuracy: 0.7916666666666666 ||AccAcc: 0.7242063492063492\n",
      "Batch_idx: 30 || Accuracy: 0.7916666666666666 ||AccAcc: 0.7674731182795702\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.8036585365853661\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 26 [0/551359 (0%)]\tLoss: 36.074535\n",
      "Batch_idx: 0 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583333333333334\n",
      "Train Epoch: 26 [240000/551359 (44%)]\tLoss: 39.597645\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9762315435123158\n",
      "Train Epoch: 26 [480000/551359 (87%)]\tLoss: 28.276455\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9762595203573147\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5416666666666666 ||AccAcc: 0.5416666666666666\n",
      "Batch_idx: 10 || Accuracy: 0.625 ||AccAcc: 0.75\n",
      "Batch_idx: 20 || Accuracy: 0.9166666666666666 ||AccAcc: 0.7400793650793652\n",
      "Batch_idx: 30 || Accuracy: 0.9166666666666666 ||AccAcc: 0.7822580645161291\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.8105691056910569\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 27 [0/551359 (0%)]\tLoss: 38.731266\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 27 [240000/551359 (44%)]\tLoss: 20.681931\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9771856147718547\n",
      "Train Epoch: 27 [480000/551359 (87%)]\tLoss: 41.791702\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.97634909921171\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5416666666666666 ||AccAcc: 0.5416666666666666\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.678030303030303\n",
      "Batch_idx: 20 || Accuracy: 0.6666666666666666 ||AccAcc: 0.6607142857142856\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.7365591397849462\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.7853658536585366\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 28 [0/551359 (0%)]\tLoss: 35.729622\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 28 [240000/551359 (44%)]\tLoss: 18.870220\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9780730260307307\n",
      "Train Epoch: 28 [480000/551359 (87%)]\tLoss: 35.178993\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9775782044231154\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.625 ||AccAcc: 0.625\n",
      "Batch_idx: 10 || Accuracy: 0.6666666666666666 ||AccAcc: 0.7613636363636364\n",
      "Batch_idx: 20 || Accuracy: 0.9166666666666666 ||AccAcc: 0.7718253968253967\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.8037634408602149\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.8300813008130081\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 29 [0/551359 (0%)]\tLoss: 39.375172\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 29 [240000/551359 (44%)]\tLoss: 45.888424\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9789604372896005\n",
      "Train Epoch: 29 [480000/551359 (87%)]\tLoss: 26.543938\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9784031631751715\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.3333333333333333 ||AccAcc: 0.3333333333333333\n",
      "Batch_idx: 10 || Accuracy: 0.625 ||AccAcc: 0.6590909090909091\n",
      "Batch_idx: 20 || Accuracy: 0.8333333333333334 ||AccAcc: 0.6607142857142857\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.7311827956989246\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.7823170731707317\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 30 [0/551359 (0%)]\tLoss: 37.773777\n",
      "Batch_idx: 0 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583333333333334\n",
      "Train Epoch: 30 [240000/551359 (44%)]\tLoss: 39.361431\n",
      "Batch_idx: 10000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9777938872779376\n",
      "Train Epoch: 30 [480000/551359 (87%)]\tLoss: 34.363918\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9778677732780041\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.2916666666666667 ||AccAcc: 0.2916666666666667\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.6553030303030303\n",
      "Batch_idx: 20 || Accuracy: 0.875 ||AccAcc: 0.6686507936507938\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7311827956989247\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.7863821138211382\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 31 [0/551359 (0%)]\tLoss: 52.633232\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 31 [240000/551359 (44%)]\tLoss: 39.658791\n",
      "Batch_idx: 10000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9805352798053538\n",
      "Train Epoch: 31 [480000/551359 (87%)]\tLoss: 38.418449\n",
      "Batch_idx: 20000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9798135093245364\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.7916666666666666 ||AccAcc: 0.7916666666666666\n",
      "Batch_idx: 10 || Accuracy: 0.625 ||AccAcc: 0.7537878787878789\n",
      "Batch_idx: 20 || Accuracy: 0.75 ||AccAcc: 0.7500000000000001\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7862903225806451\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.8178861788617887\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 32 [0/551359 (0%)]\tLoss: 35.753693\n",
      "Batch_idx: 0 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583333333333334\n",
      "Train Epoch: 32 [240000/551359 (44%)]\tLoss: 38.297855\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9805019498050195\n",
      "Train Epoch: 32 [480000/551359 (87%)]\tLoss: 39.096195\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9796385180740977\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.4583333333333333 ||AccAcc: 0.4583333333333333\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.696969696969697\n",
      "Batch_idx: 20 || Accuracy: 0.75 ||AccAcc: 0.7003968253968255\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.75\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.786178861788618\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 33 [0/551359 (0%)]\tLoss: 37.016289\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 33 [240000/551359 (44%)]\tLoss: 28.854158\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.98148101856481\n",
      "Train Epoch: 33 [480000/551359 (87%)]\tLoss: 41.978065\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9809655350565778\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5833333333333334 ||AccAcc: 0.5833333333333334\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.5946969696969696\n",
      "Batch_idx: 20 || Accuracy: 0.4583333333333333 ||AccAcc: 0.5853174603174603\n",
      "Batch_idx: 30 || Accuracy: 0.9166666666666666 ||AccAcc: 0.6653225806451615\n",
      "Batch_idx: 40 || Accuracy: 0.85 ||AccAcc: 0.7260162601626019\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 34 [0/551359 (0%)]\tLoss: 49.352566\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 34 [240000/551359 (44%)]\tLoss: 34.486084\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9822059460720581\n",
      "Train Epoch: 34 [480000/551359 (87%)]\tLoss: 18.998409\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9815175907871257\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.2916666666666667 ||AccAcc: 0.2916666666666667\n",
      "Batch_idx: 10 || Accuracy: 0.4166666666666667 ||AccAcc: 0.37121212121212116\n",
      "Batch_idx: 20 || Accuracy: 0.125 ||AccAcc: 0.3253968253968254\n",
      "Batch_idx: 30 || Accuracy: 1.0 ||AccAcc: 0.4771505376344086\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.5859756097560976\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 35 [0/551359 (0%)]\tLoss: 29.642511\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 35 [240000/551359 (44%)]\tLoss: 39.727028\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9828517148285181\n",
      "Train Epoch: 35 [480000/551359 (87%)]\tLoss: 32.014385\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.982275886205687\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.375 ||AccAcc: 0.375\n",
      "Batch_idx: 10 || Accuracy: 0.25 ||AccAcc: 0.5037878787878788\n",
      "Batch_idx: 20 || Accuracy: 0.7083333333333334 ||AccAcc: 0.5396825396825397\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.6249999999999999\n",
      "Batch_idx: 40 || Accuracy: 0.85 ||AccAcc: 0.6823170731707318\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 36 [0/551359 (0%)]\tLoss: 31.371574\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 36 [240000/551359 (44%)]\tLoss: 36.971973\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9829183748291835\n",
      "Train Epoch: 36 [480000/551359 (87%)]\tLoss: 27.047720\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9828112761028615\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5833333333333334 ||AccAcc: 0.5833333333333334\n",
      "Batch_idx: 10 || Accuracy: 0.6666666666666666 ||AccAcc: 0.7462121212121212\n",
      "Batch_idx: 20 || Accuracy: 0.875 ||AccAcc: 0.7480158730158731\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7836021505376345\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.8197154471544715\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 37 [0/551359 (0%)]\tLoss: 34.202980\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 37 [240000/551359 (44%)]\tLoss: 50.200714\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9846432023464323\n",
      "Train Epoch: 37 [480000/551359 (87%)]\tLoss: 52.046974\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9836820658967054\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.625 ||AccAcc: 0.625\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.7348484848484849\n",
      "Batch_idx: 20 || Accuracy: 0.75 ||AccAcc: 0.738095238095238\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7715053763440858\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.799390243902439\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 38 [0/551359 (0%)]\tLoss: 41.922237\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 38 [240000/551359 (44%)]\tLoss: 46.041237\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9838891110888931\n",
      "Train Epoch: 38 [480000/551359 (87%)]\tLoss: 8.771371\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9836508174591291\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.16666666666666666 ||AccAcc: 0.16666666666666666\n",
      "Batch_idx: 10 || Accuracy: 0.08333333333333333 ||AccAcc: 0.3901515151515151\n",
      "Batch_idx: 20 || Accuracy: 0.20833333333333334 ||AccAcc: 0.38095238095238093\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.49731182795698925\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.5829268292682925\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 39 [0/551359 (0%)]\tLoss: 30.486643\n",
      "Batch_idx: 0 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583333333333334\n",
      "Train Epoch: 39 [240000/551359 (44%)]\tLoss: 36.963032\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9846848648468509\n",
      "Train Epoch: 39 [480000/551359 (87%)]\tLoss: 44.991173\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9841216272519732\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.625 ||AccAcc: 0.625\n",
      "Batch_idx: 10 || Accuracy: 0.625 ||AccAcc: 0.7537878787878789\n",
      "Batch_idx: 20 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7519841269841271\n",
      "Batch_idx: 30 || Accuracy: 0.7916666666666666 ||AccAcc: 0.78494623655914\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.8158536585365856\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 40 [0/551359 (0%)]\tLoss: 22.916071\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 40 [240000/551359 (44%)]\tLoss: 12.453571\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9854347898543516\n",
      "Train Epoch: 40 [480000/551359 (87%)]\tLoss: 23.415705\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9844716097528483\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.4166666666666667 ||AccAcc: 0.4166666666666667\n",
      "Batch_idx: 10 || Accuracy: 0.625 ||AccAcc: 0.7272727272727273\n",
      "Batch_idx: 20 || Accuracy: 0.7916666666666666 ||AccAcc: 0.7242063492063493\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7701612903225807\n",
      "Batch_idx: 40 || Accuracy: 1.0 ||AccAcc: 0.8089430894308944\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 41 [0/551359 (0%)]\tLoss: 46.281517\n",
      "Batch_idx: 0 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9583333333333334\n",
      "Train Epoch: 41 [240000/551359 (44%)]\tLoss: 39.592854\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9859722361097255\n",
      "Train Epoch: 41 [480000/551359 (87%)]\tLoss: 49.336422\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9851382430878467\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5416666666666666 ||AccAcc: 0.5416666666666666\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.6704545454545454\n",
      "Batch_idx: 20 || Accuracy: 0.4583333333333333 ||AccAcc: 0.6666666666666666\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7244623655913979\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.7648373983739838\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 42 [0/551359 (0%)]\tLoss: 36.511814\n",
      "Batch_idx: 0 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9166666666666666\n",
      "Train Epoch: 42 [240000/551359 (44%)]\tLoss: 48.453918\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9853347998533484\n",
      "Train Epoch: 42 [480000/551359 (87%)]\tLoss: 45.105328\n",
      "Batch_idx: 20000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9849820008999536\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.7083333333333334 ||AccAcc: 0.7083333333333334\n",
      "Batch_idx: 10 || Accuracy: 0.5833333333333334 ||AccAcc: 0.6931818181818182\n",
      "Batch_idx: 20 || Accuracy: 0.5416666666666666 ||AccAcc: 0.6805555555555557\n",
      "Batch_idx: 30 || Accuracy: 0.8333333333333334 ||AccAcc: 0.7446236559139786\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.7892276422764228\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 43 [0/551359 (0%)]\tLoss: 21.046381\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 43 [240000/551359 (44%)]\tLoss: 22.998241\n",
      "Batch_idx: 10000 || Accuracy: 0.9166666666666666 ||AccAcc: 0.9858305836083066\n",
      "Train Epoch: 43 [480000/551359 (87%)]\tLoss: 37.852467\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9850611636084864\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.25 ||AccAcc: 0.25\n",
      "Batch_idx: 10 || Accuracy: 0.5 ||AccAcc: 0.48863636363636354\n",
      "Batch_idx: 20 || Accuracy: 0.20833333333333334 ||AccAcc: 0.4523809523809524\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.5524193548387096\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.640040650406504\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 44 [0/551359 (0%)]\tLoss: 27.185257\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 44 [240000/551359 (44%)]\tLoss: 30.554083\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9846890310968895\n",
      "Train Epoch: 44 [480000/551359 (87%)]\tLoss: 45.290035\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.985292402046561\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.4583333333333333 ||AccAcc: 0.4583333333333333\n",
      "Batch_idx: 10 || Accuracy: 0.625 ||AccAcc: 0.6931818181818182\n",
      "Batch_idx: 20 || Accuracy: 0.7083333333333334 ||AccAcc: 0.6904761904761905\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.7513440860215053\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.7943089430894308\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 45 [0/551359 (0%)]\tLoss: 39.877956\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 45 [240000/551359 (44%)]\tLoss: 40.386932\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.987067959870683\n",
      "Train Epoch: 45 [480000/551359 (87%)]\tLoss: 37.685745\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9861569421528911\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5833333333333334 ||AccAcc: 0.5833333333333334\n",
      "Batch_idx: 10 || Accuracy: 0.5416666666666666 ||AccAcc: 0.6060606060606061\n",
      "Batch_idx: 20 || Accuracy: 0.4166666666666667 ||AccAcc: 0.5952380952380952\n",
      "Batch_idx: 30 || Accuracy: 0.9166666666666666 ||AccAcc: 0.6639784946236558\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.7160569105691056\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 46 [0/551359 (0%)]\tLoss: 27.777685\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 46 [240000/551359 (44%)]\tLoss: 37.654957\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.9865055161150577\n",
      "Train Epoch: 46 [480000/551359 (87%)]\tLoss: 41.195324\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.986106944652766\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5833333333333334 ||AccAcc: 0.5833333333333334\n",
      "Batch_idx: 10 || Accuracy: 0.5416666666666666 ||AccAcc: 0.6515151515151515\n",
      "Batch_idx: 20 || Accuracy: 0.5416666666666666 ||AccAcc: 0.626984126984127\n",
      "Batch_idx: 30 || Accuracy: 0.9166666666666666 ||AccAcc: 0.7069892473118279\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.7597560975609755\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 47 [0/551359 (0%)]\tLoss: 24.374479\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 47 [240000/551359 (44%)]\tLoss: 36.974701\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9875387461253882\n",
      "Train Epoch: 47 [480000/551359 (87%)]\tLoss: 41.315910\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9870756462176876\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.5416666666666666 ||AccAcc: 0.5416666666666666\n",
      "Batch_idx: 10 || Accuracy: 0.5 ||AccAcc: 0.5946969696969696\n",
      "Batch_idx: 20 || Accuracy: 0.3333333333333333 ||AccAcc: 0.5694444444444445\n",
      "Batch_idx: 30 || Accuracy: 0.9583333333333334 ||AccAcc: 0.6411290322580645\n",
      "Batch_idx: 40 || Accuracy: 0.9 ||AccAcc: 0.7008130081300812\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 48 [0/551359 (0%)]\tLoss: 20.297453\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 48 [240000/551359 (44%)]\tLoss: 35.361782\n",
      "Batch_idx: 10000 || Accuracy: 0.9583333333333334 ||AccAcc: 0.987742892377432\n",
      "Train Epoch: 48 [480000/551359 (87%)]\tLoss: 23.717337\n",
      "Batch_idx: 20000 || Accuracy: 1.0 ||AccAcc: 0.9872131393430341\n",
      "test:\n",
      "Batch_idx: 0 || Accuracy: 0.7083333333333334 ||AccAcc: 0.7083333333333334\n",
      "Batch_idx: 10 || Accuracy: 0.4583333333333333 ||AccAcc: 0.6969696969696969\n",
      "Batch_idx: 20 || Accuracy: 0.625 ||AccAcc: 0.7083333333333333\n",
      "Batch_idx: 30 || Accuracy: 0.875 ||AccAcc: 0.7553763440860213\n",
      "Batch_idx: 40 || Accuracy: 0.95 ||AccAcc: 0.791463414634146\n",
      "----------------------------------------------------------------------------------------------------\n",
      "train:\n",
      "Train Epoch: 49 [0/551359 (0%)]\tLoss: 48.252914\n",
      "Batch_idx: 0 || Accuracy: 1.0 ||AccAcc: 1.0\n",
      "Train Epoch: 49 [240000/551359 (44%)]\tLoss: 34.514080\n",
      "Batch_idx: 10000 || Accuracy: 1.0 ||AccAcc: 0.9856306036063129\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-917b4bcd50a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_epoch\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'train:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_conv_tasnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test:'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mtest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcond_conv_tasnet\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-452eef5e0bc6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, epoch)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 43\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     44\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "n_epoch = 50\n",
    "losses = []\n",
    "\n",
    "for epoch in range(1, n_epoch + 1):\n",
    "    print('train:')\n",
    "    train(cond_conv_tasnet, epoch)\n",
    "    print('test:')\n",
    "    test(cond_conv_tasnet)\n",
    "    print('-'*100)\n",
    "    \n",
    "    PATH = './saved_model/ohot_Nigens-5M_EP_'+str(epoch)+'.pt'\n",
    "    torch.save(cond_conv_tasnet.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a1b2f38-7928-40c4-a0b7-9afc08d907f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoppp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mechanical-father",
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = './saved_model/00_wav_cond_03.pt'\n",
    "torch.save(cond_conv_tasnet.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "instant-joshua",
   "metadata": {},
   "outputs": [],
   "source": [
    "test(cond_conv_tasnet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "enabling-dining",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "nominated-mustang",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inference:\n",
    "\n",
    "spec = ['alarm','baby','crash','dog','engine','femaleScream',\n",
    "                 'femaleSpeech','fire','footsteps','knock','maleScream',\n",
    "                 'maleSpeech','phone','piano']\n",
    "\n",
    "val_dataloader = DataLoader(val_d_ds, batch_size = 150, shuffle = True, num_workers = 1) # there's also drop_last = False, collate_fn, etc.\n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "for b_no,sample_batched in enumerate(val_dataloader):\n",
    "    print(sample_batched['conditional'].size(),\n",
    "          sample_batched['sum_1_2'].size(),\n",
    "          sample_batched['separation'].size(),\n",
    "          sample_batched['pres_abs'].size())\n",
    "    \n",
    "    sum_1_2 = sample_batched['sum_1_2'].to(device) # Mixture of two ROIs\n",
    "    cond_lookUp = sample_batched['conditional'].to(device) # Conditional/What to Look for\n",
    "    target = sample_batched['separation'].to(device) # Desired Separation\n",
    "    x_target = sample_batched['pres_abs'].to(device).unsqueeze(1) # Fixing the Pres/abd binary array!\n",
    "    x_target = x_target.to(torch.float32)\n",
    "\n",
    "    \n",
    "    print(b_no)\n",
    "    \n",
    "    if(b_no == 5):\n",
    "        break\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fixed-cooperative",
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_conv_tasnet.eval()\n",
    "with torch.no_grad():\n",
    "    output, x_out = cond_conv_tasnet(wav = sum_1_2, cond_wav = cond_lookUp)\n",
    "\n",
    "import librosa.display\n",
    "\n",
    "def showSpec(y = None):\n",
    "    S = librosa.feature.melspectrogram(y=y.cpu().data.numpy().flatten(), sr=16000, n_mels=64,fmin = 0,\n",
    "                         fmax=8000, n_fft=728, hop_length=32, win_length = None, htk = True) \n",
    "    librosa.display.specshow(librosa.power_to_db(S ** 1, ref=np.max), fmin=0, y_axis='linear')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "premier-piano",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-plenty",
   "metadata": {},
   "outputs": [],
   "source": [
    "no = np.random.randint(len(target))\n",
    "print(no)\n",
    "\n",
    "print(\"Pred:\",x_out[no].cpu().data)\n",
    "print(\"GroundTruth:\",x_target[no].cpu().data)\n",
    "#print(\"LOOK FOR --\",spec[np.argmax(cond_lookUp[no].cpu().data)])\n",
    "print('-'*100)\n",
    "\n",
    "print(\"Conditional Truth:\")\n",
    "print(cond_lookUp[no].cpu().data.numpy().flatten())\n",
    "spec = ['alarm','baby','crash','dog','engine','femaleScream',\n",
    "                 'femaleSpeech','fire','footsteps','knock','maleScream',\n",
    "                 'maleSpeech','phone','piano']\n",
    "argMx = np.argmax(cond_lookUp[no].cpu().data.numpy().flatten())\n",
    "print(\">> Cond - \", spec[argMx])\n",
    "\n",
    "\n",
    "print(\"Predicted:\")\n",
    "#output[no] # Synthesized separation\n",
    "plt.plot(output[no].cpu().data.numpy().flatten()) \n",
    "plt.show()\n",
    "showSpec(y=output[no])\n",
    "ipd.display(ipd.Audio(output[no].cpu().data.numpy().flatten(), rate = 16000))\n",
    "\n",
    "\n",
    "print(\"Ground Truth:\")\n",
    "target[no] # true separation\n",
    "plt.plot(target[no].cpu().data.numpy().flatten())\n",
    "plt.show()\n",
    "showSpec(y=target[no])\n",
    "ipd.display(ipd.Audio(target[no].cpu().data.numpy().flatten(), rate = 16000))\n",
    "'''\n",
    "x_out[no] # pres/abs 1/0 flag\n",
    "print(x_out[no])\n",
    "\n",
    "x_target[no] # true pres/abs detector\n",
    "print(x_target[no])\n",
    "\n",
    "'''\n",
    "print(\"MIXTURE:\")\n",
    "sum_1_2[no] # Input Mixture\n",
    "plt.plot(sum_1_2[no].cpu().data.numpy().flatten())\n",
    "plt.show()\n",
    "showSpec(y=sum_1_2[no])\n",
    "ipd.display(ipd.Audio(sum_1_2[no].cpu().data.numpy().flatten(), rate = 16000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tracked-federation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pprint\n",
    "from asteroid.metrics import get_metrics\n",
    "\n",
    "'''metrics_dict = get_metrics(pt_mix_sam, pt_c1_sam, output, sample_rate=8000,\n",
    "                            metrics_list='all')'''\n",
    "mix = sum_1_2[no].cpu().data.numpy()\n",
    "clean = target[no].cpu().data.numpy()\n",
    "est = output[no].cpu().data.numpy()\n",
    "\n",
    "metrics_dict = get_metrics(mix, clean, est, sample_rate=8000,\n",
    "                            metrics_list='all')\n",
    "\n",
    "pprint.pprint(metrics_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "internal-ethnic",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-immigration",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blind-comment",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_pres_abs = x_target[no].cpu().data\n",
    "print(\"true_pres_abs:\",true_pres_abs.shape)\n",
    "\n",
    "pred_pres_abs = x_out[no].cpu().data\n",
    "print(\"pred_pres_abs:\",pred_pres_abs.shape)\n",
    "\n",
    "true_mix = sum_1_2[no].cpu().data.numpy().flatten()\n",
    "print(\"true_mix shape:\", true_mix.shape)aa\n",
    "\n",
    "look_for = cond_lookUp[no].cpu().data.numpy().flatten()\n",
    "print(\"look_for:\",look_for.shape)\n",
    "\n",
    "true_sep = target[no].cpu().data.numpy().flatten()\n",
    "print(\"true_sep:\", true_sep.shape)\n",
    "\n",
    "pred_sep = output[no].cpu().data.numpy().flatten()\n",
    "print(\"pred_sep:\",pred_sep.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "usual-conspiracy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import soundfile as sf\n",
    "import joblib\n",
    "\n",
    "save_here = os.path.join('./saved_sams/wav_condModel03/','good_cond_wav'+'_'+str(np.random.randint(100000)))\n",
    "#save_here = os.path.join('./saved_sams/wav_condModel03/','supress_bad__cond_wav'+'_'+str(np.random.randint(100000)))\n",
    "print(save_here)\n",
    "os.mkdir(save_here)\n",
    "joblib.dump(true_pres_abs, os.path.join(save_here,'true_pres_abs.pkl'))  \n",
    "joblib.dump(pred_pres_abs, os.path.join(save_here, 'pred_pres_abs.pkl'))\n",
    "joblib.dump(true_mix, os.path.join(save_here, 'true_mix.pkl'))\n",
    "joblib.dump(look_for, os.path.join(save_here, 'look_for.pkl'))\n",
    "joblib.dump(true_sep, os.path.join(save_here, 'true_sep.pkl'))\n",
    "joblib.dump(pred_sep, os.path.join(save_here, 'pred_sep.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "anticipated-valve",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "convenient-controversy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
